import torch
import shap
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import base64
from io import BytesIO


def explain_global_shap(testloader, combinedModel, age_scaler, bmi_scaler, gender_encoder, side_encoder,
                        presence_encoder, device="cuda"):
    """
    ëª¨ë¸ì´ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ ì–´ë–¤ íŠ¹ì„±ì„ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ”ì§€ ë¶„ì„í•˜ëŠ” Global SHAP ì„¤ëª… í•¨ìˆ˜.

    Args:
        testloader: ë°ì´í„° ë¡œë” (torch.utils.data.DataLoader).
        combinedModel: PyTorch ëª¨ë¸.
        age_scaler, bmi_scaler: ì—°ì†í˜• ë³€ìˆ˜ ë³µêµ¬ìš© Scaler.
        gender_encoder, side_encoder, presence_encoder: ë²”ì£¼í˜• ë³€ìˆ˜ ë³µêµ¬ìš© LabelEncoder.
        device: ì‹¤í–‰í•  ë””ë°”ì´ìŠ¤.

    Returns:
        SHAP Summary Plotì„ HTML íŒŒì¼ë¡œ ì €ì¥.
    """
    combinedModel.eval()
    combinedModel.to(device)

    shap_values_list = []  # ëª¨ë“  ìƒ˜í”Œì˜ SHAP ê°’ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    X_test = []  # í´ë¦¬ë‹‰ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    for batch_idx, (ids, preap_inputs, prelat_inputs, clinic_inputs, labels) in enumerate(testloader):

        preap_inputs = preap_inputs.to(device)
        prelat_inputs = prelat_inputs.to(device)
        clinic_inputs = clinic_inputs.to(device)
        labels = labels.to(device)

        for i in range(clinic_inputs.size(0)):

            # í˜„ì¬ ìƒ˜í”Œ ì¶”ì¶œ
            preap_input = preap_inputs[i].unsqueeze(0)  # (1, C, H, W)
            prelat_input = prelat_inputs[i].unsqueeze(0)  # (1, C, H, W)
            clinic_input = clinic_inputs[i].cpu().numpy().reshape(1, -1)  # (1, feature_dim).

            X_test.append(clinic_input)  # ì›ë³¸ ë°ì´í„° ì €ì¥

            # SHAP ì˜ˆì¸¡ í•¨ìˆ˜
            predict_fn = lambda x: shap_predict_fn(x, preap_input, prelat_input, combinedModel, device)

            # SHAP Explainer ìƒì„± ë° ê³„ì‚°
            explainer = shap.Explainer(predict_fn, clinic_input)
            shap_values = explainer(clinic_input)

            print("shap_values == ", shap_values.shape) #  (1, 5, 2) -> [ìƒ˜í”Œ ê°œìˆ˜, íŠ¹ì„±ê°œìˆ˜, í´ë˜ìŠ¤ ê°œìˆ˜]
            shap_values_class_0 = shap_values.values[..., 0]  # (1, 5, 2) â†’ (1, 5)
            shap_values_class_1 = shap_values.values[..., 1]  # (1, 5, 2) â†’ (1, 5)

            # ê°œë³„ ìƒ˜í”Œì˜ SHAP ê°’ì„ ì €ì¥
            shap_values_list.append(shap_values.values)  # (1, num_features) í˜•íƒœ

    # ëª¨ë“  ìƒ˜í”Œì˜ SHAP ê°’ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
    shap_values_all = np.vstack(shap_values_list)  # (num_samples, num_features)
    global_shap_values = np.mean(shap_values_all, axis=0)  # (num_features,)

    # Global SHAP Summary Plot ì €ì¥
    X_test = np.vstack(X_test)  # (ì „ì²´ ìƒ˜í”Œ ìˆ˜, feature_dim)
    encoded_shap_image = plot_shap_summary(global_shap_values, X_test, ["age", "bmi", "gender", "side", "presence"])

    # ê²°ê³¼ ì €ì¥
    save_shap_html(encoded_shap_image, "shap_global_results.html")

def shap_predict_fn(X, preap_input, prelat_input, model, device="cuda"):
    """
    SHAPì„ ìœ„í•œ ì˜ˆì¸¡ í•¨ìˆ˜ (í´ë¦¬ë‹‰ ë°ì´í„°ë§Œ ì‚¬ìš©).

    Args:
        X: ì •ê·œí™”ëœ ì„ìƒ ë°ì´í„° (numpy ë°°ì—´) (batch_size, num_features)
        preap_input: ë‹¨ì¼ ìƒ˜í”Œì˜ PreAP ì…ë ¥ í…ì„œ (1, C, H, W)
        prelat_input: ë‹¨ì¼ ìƒ˜í”Œì˜ PreLat ì…ë ¥ í…ì„œ (1, C, H, W)
        model: í›ˆë ¨ëœ PyTorch ëª¨ë¸
        device: ì‹¤í–‰í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’="cuda")

    Returns:
        ì˜ˆì¸¡ í™•ë¥ ê°’ (numpy ë°°ì—´)
    """
    model.to(device)

    # í´ë¦¬ë‹‰ ë°ì´í„°ë¥¼ pytorch tensorë¡œ ë³€í™˜
    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)

    print("X_tensor==", X_tensor.shape)         # torch.Size([1, 5])
    print("preap_input==", preap_input.shape)   # torch.Size([1, 3, 224, 224])
    print("prelat_input==", prelat_input.shape) # torch.Size([1, 3, 224, 224])

    with torch.no_grad():
        logits = model(preap_input, prelat_input, X_tensor)  # ì´ë¯¸ì§€ + í´ë¦¬ë‹‰ ë°ì´í„° ì…ë ¥
        probs = torch.softmax(logits, dim=1).cpu().numpy()

    return probs


def plot_shap_summary(global_shap_values, X, feature_names):
    """
    SHAP Summary Plotì„ ìƒì„±í•˜ì—¬ ì €ì¥.

    Args:
        global_shap_values: SHAP ë¶„ì„ ê²°ê³¼ (Global SHAP ê°’, (num_features,))
        X: ì…ë ¥ ë°ì´í„° (num_samples, num_features).
        feature_names: íŠ¹ì„± ì´ë¦„ ë¦¬ìŠ¤íŠ¸.

    Returns:
        Base64 ì¸ì½”ë”©ëœ ê·¸ë˜í”„ ì´ë¯¸ì§€.
    """
    num_samples, num_features = X.shape

    # ğŸ”¹ Global SHAP ê°’ì„ (1, num_features) â†’ (num_samples, num_features) í˜•íƒœë¡œ ë³€í™˜
    shap_values_expanded = np.tile(global_shap_values.reshape(1, -1), (num_samples, 1))

    # ğŸ”¹ ì°¨ì› í™•ì¸ (ë””ë²„ê¹…ìš©)
    print(f"X.shape: {X.shape}, shap_values_expanded.shape: {shap_values_expanded.shape}")

    # ğŸ”¹ Summary Plot ìƒì„±
    shap.summary_plot(shap_values_expanded, X, feature_names=feature_names, show=False)

    buf = BytesIO()
    plt.savefig(buf, format="png", bbox_inches='tight')
    buf.seek(0)
    encoded_image = base64.b64encode(buf.getvalue()).decode("utf-8")
    plt.close()

    return encoded_image




def save_shap_html(encoded_shap_image, file_name):
    """
    SHAP ê²°ê³¼ë¥¼ HTML íŒŒì¼ë¡œ ì €ì¥.

    Args:
        encoded_shap_image: Base64 ì¸ì½”ë”©ëœ SHAP ê·¸ë˜í”„ ì´ë¯¸ì§€.
        file_name: ì €ì¥í•  HTML íŒŒì¼ ì´ë¦„.
    """
    with open(file_name, "w") as f:
        f.write("<html><body><h2>SHAP Feature Importance</h2>\n")
        f.write("<h3>SHAP Summary Plot</h3>\n")
        f.write(f'<img src="data:image/png;base64,{encoded_shap_image}" alt="SHAP Summary">\n')
        f.write("</body></html>")
