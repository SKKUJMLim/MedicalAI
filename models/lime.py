import torch
import numpy as np
from tqdm import tqdm
import os
import matplotlib.pyplot as plt
import base64
from io import BytesIO

num_samples = 20  # perturbation ìƒ˜í”Œ ê°œìˆ˜


def explain_with_original_data_and_ranges(explanation, age_scaler, bmi_scaler, gender_encoder, side_encoder,
                                          presence_encoder):
    """
    ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ëª¨ë¸ ì˜ˆì¸¡, ì›ë³¸ ê°’ìœ¼ë¡œ ì„¤ëª… ê¸°ì¤€ì„ ë³€í™˜.

    Args:
        explanation: ì •ê·œí™”ëœ ë°ì´í„°ì— ëŒ€í•œ LIME ê²°ê³¼.
        age_scaler, bmi_scaler: ì •ê·œí™”ëœ ì—°ì†í˜• ë³€ìˆ˜ì˜ Scaler ê°ì²´.
        gender_encoder, side_encoder, presence_encoder: ë²”ì£¼í˜• ë³€ìˆ˜ ë³µì›ì„ ìœ„í•œ LabelEncoder ê°ì²´.

    Returns:
        ë³€í™˜ëœ LIME ì„¤ëª… ë¦¬ìŠ¤íŠ¸ (feature, ì›ë˜ê°’, ë³€í™˜ëœê°’, weight í˜•íƒœ).
    """
    import re

    # **ì›ë˜ feature ê°’ ê°€ì ¸ì˜¤ê¸°**
    normalized_instance = np.array(explanation.domain_mapper.feature_values).reshape(1, -1)  # (1, feature_dim)

    # ì—°ì†í˜• ë³€ìˆ˜(Age, BMI)ëŠ” Scalerë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë˜ ê°’ìœ¼ë¡œ ë³€í™˜
    original_values = [
        age_scaler.inverse_transform(normalized_instance[:, [0]].astype(float))[0][0],  # Age
        bmi_scaler.inverse_transform(normalized_instance[:, [1]].astype(float))[0][0]  # BMI
    ]

    # ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    def extract_float(value):
        match = re.search(r"[-+]?\d*\.\d+|\d+", value)
        return float(match.group()) if match else None

    # ì—°ì†í˜• ë³€ìˆ˜ ë³€í™˜ í•¨ìˆ˜
    def transform_number(value, scaler, feature_name):
        """
        ë¶€ë“±í˜¸ì™€ ìˆ«ìë¥¼ ê°œë³„ì ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì›ë˜ ê°’ì„ ë³µì›.

        Args:
            value: LIMEì´ ìƒì„±í•œ feature string (ì˜ˆ: "0.28 < bmi <= 0.37", "bmi > 0.37").
            scaler: ë³€í™˜í•  Scaler ê°ì²´.
            feature_name: ë³€í™˜í•  feature ì´ë¦„ (ì˜ˆ: 'age', 'bmi').

        Returns:
            ë³€í™˜ëœ ê°’ (ì˜ˆ: "23.79 < bmi <= 26.64" ë˜ëŠ” "bmi > 26.64").
        """
        # 1. ë²”ìœ„ ì¡°ê±´ íŒ¨í„´ (0.28 < bmi <= 0.37)
        range_pattern = r"([-+]?\d*\.\d+|\d+)\s*([<>]=?)\s*(\w+)\s*([<>]=?)\s*([-+]?\d*\.\d+|\d+)"
        range_match = re.search(range_pattern, value)

        if range_match:
            lower_num, lower_op, var, upper_op, upper_num = range_match.groups()
            lower_bound = scaler.inverse_transform([[float(lower_num)]])[0][0]
            upper_bound = scaler.inverse_transform([[float(upper_num)]])[0][0]
            return f"{lower_bound:.2f} {lower_op} {var} {upper_op} {upper_bound:.2f}"

        # 2. ë‹¨ì¼ ì¡°ê±´ íŒ¨í„´ (bmi <= 0.37)
        single_pattern = r"(\w+)\s*([<>]=?)\s*([-+]?\d*\.\d+|\d+)"
        single_match = re.search(single_pattern, value)

        if single_match:
            var, op, num = single_match.groups()
            transformed_value = scaler.inverse_transform([[float(num)]])[0][0]
            return f"{var} {op} {transformed_value:.2f}"

        return value

    # ë³€í™˜ëœ ì„¤ëª… ë¦¬ìŠ¤íŠ¸
    transformed_explanation = []

    # ì„¤ëª… ìˆ˜ì •: ì •ê·œí™”ëœ ê¸°ì¤€ì„ ì›ë³¸ ê°’ìœ¼ë¡œ ë³€í™˜
    for feature, weight in explanation.as_list():
        original_value = None  # ì›ë˜ feature ê°’
        transformed_value = None  # ë³€í™˜ëœ ê°’

        if 'age' in feature:
            scaler = age_scaler
            original_value = original_values[0]  # Age ì›ë˜ ê°’
            transformed_value = transform_number(feature, scaler, 'age')

        elif 'bmi' in feature:
            scaler = bmi_scaler
            original_value = original_values[1]  # BMI ì›ë˜ ê°’
            transformed_value = transform_number(feature, scaler, 'bmi')
        elif 'gender' in feature:
            original_value = "Male" if '1' in feature else "Female"
            transformed_value = f"{feature.split('=')[-1]} ({original_value})"

        elif 'side' in feature:
            original_value = "Right" if '1' in feature else "Left"
            transformed_value = f"{feature.split('=')[-1]} ({original_value})"

        elif 'presence' in feature:
            original_value = "Subsequent x" if '0' in feature else "Subsequent o"
            transformed_value = f"{feature.split('=')[-1]} ({original_value})"
        else:
            transformed_explanation.append((feature, None, None, weight))
            continue

        # ë³€í™˜ëœ feature ì¶”ê°€
        transformed_explanation.append((feature, original_value, transformed_value, weight))

    return transformed_explanation


def save_transformed_explanation_html(transformed_explanation, file_name, prediction_probabilities):
    """
    HTML íŒŒì¼ì— ë³€í™˜ëœ LIME ì„¤ëª… ë° ìƒëŒ€ì  ì¤‘ìš”ë„ ê·¸ë˜í”„ ì €ì¥.
    """

    # **1. Prediction Probabilities ê·¸ë˜í”„ ìƒì„±**
    fig, ax = plt.subplots(figsize=(3, 2))
    classes = [f"Class {i}" for i in range(len(prediction_probabilities))]
    bars = ax.bar(classes, prediction_probabilities, color=['blue', 'orange'])
    ax.set_ylim(0, 1)
    ax.set_ylabel("Probability")
    ax.set_title("Prediction Probabilities")

    # **1.1 ë§‰ëŒ€ ìœ„ì— í´ë˜ìŠ¤ëª… ì¶”ê°€**
    for bar, class_name in zip(bars, classes):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width() / 2, height + 0.02, class_name, ha='center', fontsize=10,
                fontweight='bold')

    # **2. Prediction Probabilities ê·¸ë˜í”„ â†’ Base64 ë³€í™˜**
    buf = BytesIO()
    plt.savefig(buf, format="png", bbox_inches='tight')
    buf.seek(0)
    encoded_prob_image = base64.b64encode(buf.getvalue()).decode("utf-8")
    plt.close(fig)

    # **3. clinic_inputs Feature Importance ê³„ì‚°**
    feature_importance = compute_relative_importance(transformed_explanation)

    # **3.1 ê° Featureê°€ Class 0ì¸ì§€ Class 1ì— ê¸°ì—¬í•˜ëŠ”ì§€ ì¶”ì¶œ (ì˜¬ë°”ë¥´ê²Œ ìˆ˜ì •ëœ ë¶€ë¶„)**
    feature_contributions = {}
    for feature, _, _, weight in transformed_explanation:
        weight_float = float(weight) if weight is not None else 0.0
        contribution = "Class 1 [Surgery required (Yes)]" if weight_float > 0 else "Class 0 [Surgery not required (No)]"
        feature_contributions[feature] = contribution

    # **4. Feature Importance ë°” ê·¸ë˜í”„ ìƒì„± (Classë³„ ìƒ‰ìƒ ë°˜ì˜)**
    encoded_importance_image = plot_relative_importance(feature_importance, feature_contributions)

    # **5. HTML ìƒì„±**
    with open(file_name, 'w') as f:
        f.write("<html><body><h2>Transformed Explanation</h2>\n")

        # **Prediction Probabilities ê·¸ë˜í”„**
        f.write("<h3>Prediction Probabilities</h3>\n")
        f.write(f'<img src="data:image/png;base64,{encoded_prob_image}" alt="Prediction Probabilities">\n')

        # **Relative Importance ë°” ê·¸ë˜í”„ (ìƒˆë¡œìš´ <h3> íƒœê·¸ ì¶”ê°€)**
        f.write("<h3>Relative Importance of Features</h3>\n")
        f.write(f'<img src="data:image/png;base64,{encoded_importance_image}" alt="Relative Importance">\n')

        # **Feature Contributions Table**
        f.write("<h3>Feature Contributions</h3>\n")
        f.write("<table border='1'>\n")
        f.write(
            "<tr><th>Feature</th><th>Original Value</th><th>Transformed Value</th><th>Weight</th><th>Contribution</th><th>Relative Importance</th></tr>\n")

        clinic_features = ['age', 'bmi', 'gender', 'side', 'presence']

        for feature, original_value, transformed_value, weight in transformed_explanation:
            original_value = original_value if original_value is not None else "N/A"
            transformed_value = transformed_value if transformed_value is not None else "N/A"
            weight_str = f"{weight:.6f}" if weight is not None else "N/A"

            # **Weight ë¶€í˜¸ë§Œ íŒë‹¨í•˜ì—¬ ê¸°ì—¬ë„ ê²°ì •**
            try:
                weight_float = float(weight)
                contribution = "Class 1 [Surgery required (Yes)]" if weight_float > 0 else "Class 0 [Surgery not required (No)]"
            except ValueError:
                contribution = "N/A"

            # **Relative Importance ê°’ ì°¾ê¸° (ì •í™•í•œ ë§¤ì¹­)**
            relative_importance = 0.0
            for key in clinic_features:
                if key in feature:  # ì •í™•í•œ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸
                    relative_importance = feature_importance.get(key, 0.0)
                    break  # í•˜ë‚˜ë§Œ ë§¤ì¹­ë˜ë©´ ì¤‘ë‹¨

            rel_importance_str = f"{relative_importance:.6f}"  # ğŸ”¥ ì†Œìˆ˜ì  6ìë¦¬ ì¶œë ¥

            f.write(
                f"<tr><td>{feature}</td><td>{original_value}</td><td>{transformed_value}</td><td>{weight_str}</td><td>{contribution}</td><td>{rel_importance_str}</td></tr>\n")

        f.write("</table></body></html>")


def plot_relative_importance(feature_importance, feature_contributions):
    """
    Feature Importanceë¥¼ ë°” ê·¸ë˜í”„ë¡œ ì‹œê°í™”í•˜ë©°, Class 0 / Class 1 ê¸°ì—¬ ì—¬ë¶€ì— ë”°ë¼ ìƒ‰ìƒì„ ë‹¤ë¥´ê²Œ ì ìš©.
    """
    features, importance = list(feature_importance.keys()), list(feature_importance.values())

    # **ê° Featureê°€ Class 0ì¸ì§€ Class 1ì— ê¸°ì—¬í•˜ëŠ”ì§€ í™•ì¸ (ì •í™•í•œ ë§¤ì¹­)**
    def get_contribution_label(feature):
        for key in feature_contributions:
            if feature.startswith(key) or key.startswith(feature):
                return feature_contributions[key]
        return "Class 0 [Surgery not required (No)]"  # ê¸°ë³¸ê°’: Class 0

    colors = ['blue' if "Class 0" in get_contribution_label(feat) else 'orange' for feat in features]

    fig, ax = plt.subplots(figsize=(5, 3))
    bars = ax.barh(features, importance, color=colors)
    ax.set_xlabel("Relative Importance")
    ax.set_title("Feature Importance (Class 0 = Blue, Class 1 = Orange)", fontsize=12, fontweight='bold')

    # **ë§‰ëŒ€ ìœ„ì— ì¤‘ìš”ë„ ê°’ ì¶”ê°€**
    for bar, value, color in zip(bars, importance, colors):
        width = bar.get_width()
        ax.text(width + 0.01, bar.get_y() + bar.get_height() / 2, f"{value:.4f}",
                ha='left', fontsize=9, fontweight='bold', color=color)

    buf = BytesIO()
    plt.savefig(buf, format="png", bbox_inches='tight')
    buf.seek(0)
    encoded_image = base64.b64encode(buf.getvalue()).decode("utf-8")
    plt.close(fig)

    return encoded_image


def compute_relative_importance(transformed_explanation):
    """
    clinic_inputs ë‚´ë¶€ featureë“¤ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ë¥¼ ì •ê·œí™”í•˜ì—¬ ê³„ì‚°.
    """
    clinic_features = ['age', 'bmi', 'gender', 'side', 'presence']
    feature_weights = {feat: 0 for feat in clinic_features}

    for feature, _, _, weight in transformed_explanation:
        for key in clinic_features:
            if key in feature:
                feature_weights[key] += abs(weight)

    total_weight = sum(feature_weights.values())
    if total_weight > 0:
        feature_importance = {key: feature_weights[key] / total_weight for key in clinic_features}
    else:
        feature_importance = {key: 0 for key in clinic_features}

    return feature_importance


def save_all_lime_results(explanations, age_scaler, bmi_scaler, gender_encoder, side_encoder, presence_encoder,
                          base_dir="lime_results"):
    """
    ëª¨ë“  LIME ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ì— HTML íŒŒì¼ë¡œ ì €ì¥.

    Args:
        explanations: LIME ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (sample_id, label, explanation í˜•íƒœ).
        base_dir: ê²°ê³¼ë¥¼ ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬. ê¸°ë³¸ê°’ì€ 'lime_results'.
    """
    # í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(f"{base_dir}/0", exist_ok=True)
    os.makedirs(f"{base_dir}/1", exist_ok=True)

    # íŠ¹ì • ìƒ˜í”Œì— ëŒ€í•œ ì„¤ëª… ì¶œë ¥
    for sample_id, label, explanation in explanations:
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        file_name = f"{base_dir}/{label}/lime_explanation_sample_{sample_id}.html"

        # ëª¨ë¸ ì˜ˆì¸¡ í™•ë¥  ê°€ì ¸ì˜¤ê¸°
        prediction_probabilities = explanation.predict_proba

        # ì •ê·œí™”ëœ ë°ì´í„°ì—ì„œ ì›ë³¸ ê°’ìœ¼ë¡œ ì„¤ëª… ê¸°ì¤€ì„ ë³€í™˜.
        transformed_explanation = explain_with_original_data_and_ranges(explanation,
                                                                        age_scaler=age_scaler,
                                                                        bmi_scaler=bmi_scaler,
                                                                        gender_encoder=gender_encoder,
                                                                        side_encoder=side_encoder,
                                                                        presence_encoder=presence_encoder)

        # HTML íŒŒì¼ë¡œ ì €ì¥
        try:
            explanation.save_to_file(file_name)
            save_transformed_explanation_html(transformed_explanation, f"{file_name}.html", prediction_probabilities)
            # print(f"Explanation for sample {sample_id} saved to {file_name}")
        except Exception as e:
            print(f"Error saving explanation for sample {sample_id}: {e}")


def predict_fn_for_lime(data, preap_input, prelat_input, combinedModel, batch_size=32):
    # def predict_fn_for_lime(data, preap_input, prelat_input, combinedModel):
    """
    LIMEì´ í˜¸ì¶œí•  ì˜ˆì¸¡ í•¨ìˆ˜. ë³€í˜•ëœ í…Œì´ë¸” ë°ì´í„°ì™€ ê³ ì •ëœ preap_input ë° prelat_inputì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ í™•ë¥  ë°˜í™˜.

    Args:
        data: LIMEì´ ë³€í˜•í•œ í´ë¦¬ë‹‰ ë°ì´í„° (numpy ë°°ì—´, ë°°ì¹˜ í˜•íƒœ).
        preap_input: ê³ ì •ëœ preap_input (torch.Tensor).
        prelat_input: ê³ ì •ëœ prelat_input (torch.Tensor).
        combinedModel: CombinedModel (PyTorch ëª¨ë¸).

    Returns:
        í™•ë¥ ê°’ ë°°ì—´ (numpy).
    """

    # combinedModel.to(preap_input.device)

    # print("data.shape == ", data.shape) # LIMEì´ ë³€í˜•í•œ í´ë¦¬ë‹‰ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì— ì°¨ì›ì´ ë†’ë‹¤

    # LIME ë³€í˜• ë°ì´í„°ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
    clinic_input = torch.tensor(data, dtype=torch.float32).to(preap_input.device)
    # ë°°ì¹˜ë¡œ perturbationì„ ë‚˜ëˆ„ì–´ì„œ ì‹¤í–‰
    probs_list = []
    for i in range(0, len(clinic_input), batch_size):
        batch_clinic_input = clinic_input[i:i + batch_size]
        preap_batch = preap_input.expand(batch_clinic_input.size(0), -1, -1, -1)
        prelat_batch = prelat_input.expand(batch_clinic_input.size(0), -1, -1, -1)

        with torch.no_grad():
            logits = combinedModel(preap_batch, prelat_batch, batch_clinic_input)
            probs = torch.softmax(logits, dim=1).cpu().numpy()
            probs_list.extend(probs)

    return np.array(probs_list)

    # ì›ë³¸ ë²„ì ¼
    # batch_size = clinic_input.size(0) # LIMEì´ ë³€í˜•í•œ í´ë¦¬ë‹‰ ë°ì´í„°ì™€ batchë¥¼ ë§ì¶˜ë‹¤.

    # preap_input = preap_input.expand(batch_size, -1, -1, -1)  # ë™ì¼í•œ ê°’ì„ ë°°ì¹˜ í¬ê¸°ë§Œí¼ í™•ì¥
    # prelat_input = prelat_input.expand(batch_size, -1, -1, -1)

    # with torch.no_grad():
    #     logits = combinedModel(preap_input, prelat_input, clinic_input)
    #     probs = torch.softmax(logits, dim=1).cpu().numpy()

    # return probs


def explain_instance(testloader, explainer, combinedModel, device='cuda', max_samples=20):
    """
       ë°°ì¹˜ ë°ì´í„°ì—ì„œ ê° ìƒ˜í”Œì— ëŒ€í•´ LIME ì„¤ëª…ì„ ìƒì„±.

       Args:
           testloader: ë°ì´í„° ë¡œë” (torch.utils.data.DataLoader).
           explainer: LimeTabularExplainer ê°ì²´.
           combinedModel: CombinedModel (PyTorch ëª¨ë¸).
           device: GPU ë˜ëŠ” CPU.
       Returns:
           list: ê° ìƒ˜í”Œì— ëŒ€í•œ LIME ì„¤ëª… ê°ì²´ ë¦¬ìŠ¤íŠ¸.
       """

    combinedModel.eval()
    combinedModel.to(device)
    explanations = []
    samples_processed = 0

    for batch_idx, (ids, preap_inputs, prelat_inputs, clinic_inputs, labels) in tqdm(enumerate(testloader),
                                                                                     total=len(testloader),
                                                                                     desc="Calculating LIME"):
        preap_inputs = preap_inputs.to(device)
        prelat_inputs = prelat_inputs.to(device)
        clinic_inputs = clinic_inputs.to(device)
        labels = labels.to(device)

        for i in range(clinic_inputs.size(0)):

            # ë§Œì•½ ì´ë¯¸ max_samples ê°œë¥¼ ë„˜ì—ˆë‹¤ë©´ ì¡°ê¸° ì¢…ë£Œ
            if samples_processed >= max_samples:
                break

            # í˜„ì¬ ìƒ˜í”Œ ì¶”ì¶œ
            id = ids[i]
            preap_input = preap_inputs[i].unsqueeze(0)  # (1, C, H, W)
            prelat_input = prelat_inputs[i].unsqueeze(0)  # (1, C, H, W)
            # clinic_input = clinic_inputs[i].unsqueeze(0)
            clinic_input = clinic_inputs[i].cpu().numpy()  # LIMEì€ numpy ë°°ì—´ ì‚¬ìš©
            label = labels[i].item()

            # print("clinic_input == ", clinic_input)

            # LIME ì„¤ëª… ìƒì„±
            def lime_predict_fn(data):
                # print("lime_predict_fn data == ", data)
                return predict_fn_for_lime(data, preap_input, prelat_input, combinedModel)

            num_features = clinic_input.shape[0]  # ì„¤ëª…í•  í´ë¦¬ë‹‰ ë°ì´í„° feature ê°œìˆ˜

            explanation = explainer.explain_instance(
                clinic_input,  # ì„¤ëª…í•  í´ë¦¬ë‹‰ ë°ì´í„° (ê°œë³„ ìƒ˜í”Œ)
                lime_predict_fn,  # ë³€í˜•ëœ ë°ì´í„° ì˜ˆì¸¡ í•¨ìˆ˜, ì›ë³¸ ë°ì´í„°ë¥¼ ë³€í˜•í•˜ëŠ” ì´ìœ ëŠ” ëª¨ë¸ì´ íŠ¹ì • íŠ¹ì„±(feature)ì— ì–¼ë§ˆë‚˜ ì˜ì¡´í•˜ëŠ”ì§€ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œ
                num_features=num_features,
                num_samples=num_samples  # perturbation ìƒ˜í”Œ ê°œìˆ˜
            )
            explanations.append((id, label, explanation))
            samples_processed += 1

        # ë°°ì¹˜ ë£¨í”„ íƒˆì¶œ ì¡°ê±´
        if samples_processed >= max_samples:
            break

    return explanations