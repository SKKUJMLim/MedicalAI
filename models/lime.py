import torch
import torch.nn as nn
import numpy as np
from tqdm import tqdm
import os
import sys
import re


num_samples = 10 # perturbation ìƒ˜í”Œ ê°œìˆ˜

def explain_with_original_data_and_ranges(explanation, age_scaler, bmi_scaler, gender_encoder, side_encoder, presence_encoder):
    """
    ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ëª¨ë¸ ì˜ˆì¸¡, ì›ë³¸ ê°’ìœ¼ë¡œ ì„¤ëª… ê¸°ì¤€ì„ ë³€í™˜.

    Args:
        explanation: ì •ê·œí™”ëœ ë°ì´í„°ì— ëŒ€í•œ LIME ê²°ê³¼.
        age_scaler, bmi_scaler: ì •ê·œí™”ëœ ì—°ì†í˜• ë³€ìˆ˜ì˜ Scaler ê°ì²´.
        gender_encoder, side_encoder, presence_encoder: ë²”ì£¼í˜• ë³€ìˆ˜ ë³µì›ì„ ìœ„í•œ LabelEncoder ê°ì²´.

    Returns:
        ë³€í™˜ëœ LIME ì„¤ëª… ë¦¬ìŠ¤íŠ¸ (feature, ì›ë˜ê°’, ë³€í™˜ëœê°’, weight í˜•íƒœ).
    """
    import re

    # **ì›ë˜ feature ê°’ ê°€ì ¸ì˜¤ê¸°**
    normalized_instance = np.array(explanation.domain_mapper.feature_values).reshape(1, -1)  # (1, feature_dim)

    # ì—°ì†í˜• ë³€ìˆ˜(Age, BMI)ëŠ” Scalerë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë˜ ê°’ìœ¼ë¡œ ë³€í™˜
    original_values = [
        age_scaler.inverse_transform(normalized_instance[:, [0]].astype(float))[0][0],  # Age
        bmi_scaler.inverse_transform(normalized_instance[:, [1]].astype(float))[0][0]   # BMI
    ]

    gender_value = -1  # ì˜ˆì™¸ì²˜ë¦¬ëœ ê²½ìš°ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ê¸°ë³¸ê°’ ì„¤ì • (ex: -1)
    side_value = -1  # ì˜ˆì™¸ì²˜ë¦¬ëœ ê²½ìš°ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ê¸°ë³¸ê°’ ì„¤ì • (ex: -1)
    presence_value = -1  # ì˜ˆì™¸ì²˜ë¦¬ëœ ê²½ìš°ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆë„ë¡ ê¸°ë³¸ê°’ ì„¤ì • (ex: -1)

    print("gender_value == ", normalized_instance[:, 2][0])
    print("side_value == ", normalized_instance[:, 3][0])
    print("presence_value == ", normalized_instance[:, 4][0])

    # ë²”ì£¼í˜• ë³€ìˆ˜(Gender, Side, Presence)ëŠ” LabelEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë˜ ê°’ ë³µì›
    try:
        gender_value = int(float(normalized_instance[:, 2][0]))
        side_value = int(float(normalized_instance[:, 3][0]))
        presence_value = int(float(normalized_instance[:, 4][0]))

        gender_text = gender_encoder.inverse_transform(np.array([gender_value]).astype(int))[0]
        side_text = side_encoder.inverse_transform(np.array([side_value]).astype(int))[0]
        presence_text = presence_encoder.inverse_transform(np.array([presence_value]).astype(int))[0]
    except ValueError as e:
        print(f"Error converting categorical values: {e}")
        gender_text, side_text, presence_text = "Unknown", "Unknown", "Unknown"

    # ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    def extract_float(value):
        match = re.search(r"[-+]?\d*\.\d+|\d+", value)
        return float(match.group()) if match else None

    # ìˆ«ìë¥¼ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ì—°ì†í˜• ë³€ìˆ˜ë§Œ)
    def transform_number(value, scaler):
        number = extract_float(value)
        if number is not None:
            try:
                return f"{scaler.inverse_transform(np.array([[number]]))[0][0]:.2f}"
            except ValueError:
                return value
        return value

    # ë³€í™˜ëœ ì„¤ëª… ë¦¬ìŠ¤íŠ¸
    transformed_explanation = []

    # ì„¤ëª… ìˆ˜ì •: ì •ê·œí™”ëœ ê¸°ì¤€ì„ ì›ë³¸ ê°’ìœ¼ë¡œ ë³€í™˜
    for feature, weight in explanation.as_list():
        original_value = None  # ì›ë˜ feature ê°’
        transformed_value = None  # ë³€í™˜ëœ ê°’

        if 'age' in feature:
            scaler = age_scaler
            original_value = original_values[0]  # Age ì›ë˜ ê°’
            transformed_value = transform_number(feature, scaler)

        elif 'bmi' in feature:
            scaler = bmi_scaler
            original_value = original_values[1]  # BMI ì›ë˜ ê°’
            transformed_value = transform_number(feature, scaler)

        elif 'gender' in feature:
            original_value = gender_text  # Gender ì›ë˜ ê°’
            transformed_value = f"{gender_value} ({gender_text})"

        elif 'side' in feature:
            original_value = side_text  # Side ì›ë˜ ê°’
            transformed_value = f"{side_value} ({side_text})"

        elif 'presence' in feature:
            original_value = presence_text  # Presence ì›ë˜ ê°’
            transformed_value = f"{presence_value} ({presence_text})"

        else:
            transformed_explanation.append((feature, None, None, weight))
            continue

        # ë³€í™˜ëœ feature ì¶”ê°€
        transformed_explanation.append((feature, original_value, transformed_value, weight))

    return transformed_explanation

def save_transformed_explanation_html(transformed_explanation, file_name):
    """
    ë³€í™˜ëœ ì„¤ëª…ì„ HTML íŒŒì¼ë¡œ ì €ì¥í•˜ë©°, ì»¬ëŸ¼ ìˆœì„œë¥¼ `age -> gender -> side -> presence`ë¡œ ì •ë ¬.

    Args:
        transformed_explanation: ë³€í™˜ëœ ì„¤ëª… ë¦¬ìŠ¤íŠ¸ (feature, ì›ë˜ê°’, ë³€í™˜ëœê°’, weight í˜•íƒœ).
        file_name: ì €ì¥í•  íŒŒì¼ ì´ë¦„.
    """
    # ğŸ¯ **ìˆœì„œëŒ€ë¡œ ì •ë ¬**
    sorted_features = ["age", "bmi", "gender", "side", "presence"]  # ì›í•˜ëŠ” ì •ë ¬ ìˆœì„œ
    sorted_explanation = sorted(
        transformed_explanation,
        key=lambda x: sorted_features.index(x[0].split(" ")[0]) if x[0].split(" ")[0] in sorted_features else len(sorted_features)
    )

    with open(file_name, 'w') as f:
        f.write("<html><body><h2>Transformed Explanation</h2>\n")
        f.write("<table border='1'>\n")
        f.write("<tr><th>Feature</th><th>Original Value</th><th>Transformed Value</th><th>Weight</th></tr>\n")

        for feature, original_value, transformed_value, weight in sorted_explanation:
            original_value = original_value if original_value is not None else "N/A"
            transformed_value = transformed_value if transformed_value is not None else "N/A"
            weight = f"{weight:.4f}" if weight is not None else "N/A"

            f.write(f"<tr><td>{feature}</td><td>{original_value}</td><td>{transformed_value}</td><td>{weight}</td></tr>\n")

        f.write("</table></body></html>")


def save_all_lime_results(explanations, age_scaler, bmi_scaler, gender_encoder, side_encoder, presence_encoder, base_dir="lime_results"):
    """
    ëª¨ë“  LIME ê²°ê³¼ë¥¼ í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ì— HTML íŒŒì¼ë¡œ ì €ì¥.

    Args:
        explanations: LIME ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (sample_id, label, explanation í˜•íƒœ).
        base_dir: ê²°ê³¼ë¥¼ ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬. ê¸°ë³¸ê°’ì€ 'lime_results'.
    """
    # í´ë˜ìŠ¤ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(f"{base_dir}/0", exist_ok=True)
    os.makedirs(f"{base_dir}/1", exist_ok=True)

    # íŠ¹ì • ìƒ˜í”Œì— ëŒ€í•œ ì„¤ëª… ì¶œë ¥
    for sample_id, label, explanation in explanations:
        # íŒŒì¼ ê²½ë¡œ ì„¤ì •
        file_name = f"{base_dir}/{label}/lime_explanation_sample_{sample_id}.html"

        # ì •ê·œí™”ëœ ë°ì´í„°ì—ì„œ ì›ë³¸ ê°’ìœ¼ë¡œ ì„¤ëª… ê¸°ì¤€ì„ ë³€í™˜.
        transformed_explanation = explain_with_original_data_and_ranges(explanation,
                                                                        age_scaler=age_scaler,
                                                                        bmi_scaler=bmi_scaler,
                                                                        gender_encoder=gender_encoder,
                                                                        side_encoder=side_encoder,
                                                                        presence_encoder=presence_encoder)

        # HTML íŒŒì¼ë¡œ ì €ì¥
        try:
            explanation.save_to_file(file_name)
            save_transformed_explanation_html(transformed_explanation, f"{file_name}.html")
            # print(f"Explanation for sample {sample_id} saved to {file_name}")
        except Exception as e:
            print(f"Error saving explanation for sample {sample_id}: {e}")


def predict_fn_for_lime(data, preap_input, prelat_input, combinedModel, batch_size=32):
    # def predict_fn_for_lime(data, preap_input, prelat_input, combinedModel):
    """
    LIMEì´ í˜¸ì¶œí•  ì˜ˆì¸¡ í•¨ìˆ˜. ë³€í˜•ëœ í…Œì´ë¸” ë°ì´í„°ì™€ ê³ ì •ëœ preap_input ë° prelat_inputì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ì˜ˆì¸¡ í™•ë¥  ë°˜í™˜.

    Args:
        data: LIMEì´ ë³€í˜•í•œ í´ë¦¬ë‹‰ ë°ì´í„° (numpy ë°°ì—´, ë°°ì¹˜ í˜•íƒœ).
        preap_input: ê³ ì •ëœ preap_input (torch.Tensor).
        prelat_input: ê³ ì •ëœ prelat_input (torch.Tensor).
        combinedModel: CombinedModel (PyTorch ëª¨ë¸).

    Returns:
        í™•ë¥ ê°’ ë°°ì—´ (numpy).
    """

    combinedModel.to(preap_input.device)

    # print("data.shape == ", data.shape) # LIMEì´ ë³€í˜•í•œ í´ë¦¬ë‹‰ ë°ì´í„°ì´ê¸° ë•Œë¬¸ì— ì°¨ì›ì´ ë†’ë‹¤

    # LIME ë³€í˜• ë°ì´í„°ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
    clinic_input = torch.tensor(data, dtype=torch.float32).to(preap_input.device)
    # ë°°ì¹˜ë¡œ perturbationì„ ë‚˜ëˆ„ì–´ì„œ ì‹¤í–‰
    probs_list = []
    for i in range(0, len(clinic_input), batch_size):
        batch_clinic_input = clinic_input[i:i + batch_size]
        preap_batch = preap_input.expand(batch_clinic_input.size(0), -1, -1, -1)
        prelat_batch = prelat_input.expand(batch_clinic_input.size(0), -1, -1, -1)

        with torch.no_grad():
            logits = combinedModel(preap_batch, prelat_batch, batch_clinic_input)
            probs = torch.softmax(logits, dim=1).cpu().numpy()
            probs_list.extend(probs)

    return np.array(probs_list)

    #ì›ë³¸ ë²„ì ¼
    # batch_size = clinic_input.size(0) # LIMEì´ ë³€í˜•í•œ í´ë¦¬ë‹‰ ë°ì´í„°ì™€ batchë¥¼ ë§ì¶˜ë‹¤.

    # preap_input = preap_input.expand(batch_size, -1, -1, -1)  # ë™ì¼í•œ ê°’ì„ ë°°ì¹˜ í¬ê¸°ë§Œí¼ í™•ì¥
    # prelat_input = prelat_input.expand(batch_size, -1, -1, -1)

    # with torch.no_grad():
    #     logits = combinedModel(preap_input, prelat_input, clinic_input)
    #     probs = torch.softmax(logits, dim=1).cpu().numpy()

    # return probs


def explain_instance(testloader, explainer, combinedModel, device='cuda', max_samples= 20):
    """
       ë°°ì¹˜ ë°ì´í„°ì—ì„œ ê° ìƒ˜í”Œì— ëŒ€í•´ LIME ì„¤ëª…ì„ ìƒì„±.

       Args:
           testloader: ë°ì´í„° ë¡œë” (torch.utils.data.DataLoader).
           explainer: LimeTabularExplainer ê°ì²´.
           combinedModel: CombinedModel (PyTorch ëª¨ë¸).
           device: GPU ë˜ëŠ” CPU.
       Returns:
           list: ê° ìƒ˜í”Œì— ëŒ€í•œ LIME ì„¤ëª… ê°ì²´ ë¦¬ìŠ¤íŠ¸.
       """

    combinedModel.eval()
    combinedModel.to(device)
    explanations = []
    samples_processed = 0

    for batch_idx, (ids, preap_inputs, prelat_inputs, clinic_inputs, labels) in tqdm(enumerate(testloader),
                                                                                     total=len(testloader),
                                                                                     desc="Calculating LIME"):
        preap_inputs = preap_inputs.to(device)
        prelat_inputs = prelat_inputs.to(device)
        clinic_inputs = clinic_inputs.to(device)
        labels = labels.to(device)

        for i in range(clinic_inputs.size(0)):

            # ë§Œì•½ ì´ë¯¸ max_samples ê°œë¥¼ ë„˜ì—ˆë‹¤ë©´ ì¡°ê¸° ì¢…ë£Œ
            if samples_processed >= max_samples:
                break

            # í˜„ì¬ ìƒ˜í”Œ ì¶”ì¶œ
            id = ids[i]
            preap_input = preap_inputs[i].unsqueeze(0)  # (1, C, H, W)
            prelat_input = prelat_inputs[i].unsqueeze(0)  # (1, C, H, W)
            # clinic_input = clinic_inputs[i].unsqueeze(0)
            clinic_input = clinic_inputs[i].cpu().numpy()  # LIMEì€ numpy ë°°ì—´ ì‚¬ìš©
            label = labels[i].item()

            # print("clinic_input == ", clinic_input)

            # LIME ì„¤ëª… ìƒì„±
            def lime_predict_fn(data):
                # print("lime_predict_fn data == ", data)
                return predict_fn_for_lime(data, preap_input, prelat_input, combinedModel)

            num_features = clinic_input.shape[0]  # ì„¤ëª…í•  í´ë¦¬ë‹‰ ë°ì´í„° feature ê°œìˆ˜

            explanation = explainer.explain_instance(
                clinic_input,  # ì„¤ëª…í•  í´ë¦¬ë‹‰ ë°ì´í„° (ê°œë³„ ìƒ˜í”Œ)
                lime_predict_fn,  # ë³€í˜•ëœ ë°ì´í„° ì˜ˆì¸¡ í•¨ìˆ˜, ì›ë³¸ ë°ì´í„°ë¥¼ ë³€í˜•í•˜ëŠ” ì´ìœ ëŠ” ëª¨ë¸ì´ íŠ¹ì • íŠ¹ì„±(feature)ì— ì–¼ë§ˆë‚˜ ì˜ì¡´í•˜ëŠ”ì§€ ë¶„ì„í•˜ê¸° ìœ„í•´ì„œ
                num_features=num_features,
                num_samples=num_samples  # perturbation ìƒ˜í”Œ ê°œìˆ˜
            )
            explanations.append((id, label, explanation))
            samples_processed += 1
            
        # ë°°ì¹˜ ë£¨í”„ íƒˆì¶œ ì¡°ê±´
        if samples_processed >= max_samples:
            break

    return explanations